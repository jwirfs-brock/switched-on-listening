<!doctype html>
<html lang="en">
  <head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!-- Bootstrap CSS -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-+0n0xVW2eSR5OomGNYDnhzAbDsOXxcvSN1TPprVMTNDbiYZCxYbOOl7+AMvyTG2x" crossorigin="anonymous">


    <title>Switched on Listening - ICAD 2021</title>


  </head>
  <body>

    <!-- Bootstrap Bundle with Popper -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.1/dist/js/bootstrap.bundle.min.js" integrity="sha384-gtEjrD/SeCtmISkJkNUaaKMoLD0//ElJ19smozuHV6z3Iehds+3Ulb9Bn9Plx0x4" crossorigin="anonymous"></script>

    <nav class="navbar sticky-top navbar-expand-lg navbar-light bg-light">
    <div class="container-fluid">
      <a class="navbar-brand" href="#">Switched on Listening</a>
      <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>
      <div class="collapse navbar-collapse" id="navbarSupportedContent">
        <ul class="navbar-nav me-auto mb-2 mb-lg-0">
          <li class="nav-item">
            <a class="nav-link active" aria-current="page" href="#Overview">Overview</a>
          </li>


          <li class="nav-item">
            <a class="nav-link" href="#Video">The Video</a>
          </li>

          <li class="nav-item">
            <a class="nav-link" href="#Artifacts">Methods</a>
          </li>

          <li class="nav-item">
            <a class="nav-link" href="#Findings">Findings</a>
          </li>

          <li class="nav-item">
            <a class="nav-link" href="#FutureWork">Future Work</a>
          </li>

          <li class="nav-item">
            <a class="nav-link" href="#Extras">Extras</a>
          </li>


        </ul>

      </div>
    </div>
</nav>

<div class="p-5 mb-4 bg-info rounded-3 ">
  <div class="container-fluid py-5">
    <h1 class="display-1 fw-bold">Switched on Listening</h1>
    <h2 class="display-5 fw-bold">What Auditory Display Designers Can Learn from Video Analysis</h2>
    <div style="max-width:350px" class="float-end">
      <img  src="files/video-doodle.png" width="95%">
    </div>
    <p class="col-md-8 fs-5">This work analyzes video of a live performance of <em>Switched on Pop</em>, a podcast that teaches people how to listen closely to music—with the goal of understanding interactions that can help people learn to listen to sounds analytically.</p>
<p class="col-md-8 fs-6"><em>Jordan Wirfs-Brock, University of Colorado</em></p>
<p class="col-md-8 fs-6">ICAD 2021</p>
  </div>
</div>

<div class="container-fluid p-5 mb-4 rounded-1 pt-0"><a id="Overview" style="display: block; position: relative; top: -300px; visibility: hidden;"></a>
  <h2 class="display-9 fw-bold col-md-8">Overview: Focusing on Sonic Sensemaking</h2>
  <dl class="row">
    <dt class="col-sm-3">Research Question</dt>
    <dd class="col-sm-9">What techniques can support people as they learn how to listen to sounds analytically?</dd>

    <dt class="col-sm-3">Approach</dt>
    <dd class="col-sm-9">
      <p>I explore this question through video analysis of a live performance of <a href="https://switchedonpop.com/"><em>Switched on Pop</em></a>, a podcast that teaches people how to listen closely to pop music.</p>
    </dd>

    <dt class="col-sm-3">If my focus is sonification, why turn to pop music?</dt>
    <dd class="col-sm-9">
      <div style="max-width:240px" class="float-end">
        <img  src="files/junk-food-ears.gif" width="100%">
      </div>
      <em>Switched on Pop</em> takes the stance that pop music isn't just junk food for your ears; rather, it’s a powerful vehicle to understand musical concepts like song structure and chord progression.
      On the podcast, they use a variety of <strong>techniques to teach sonic concepts</strong>, including: repetition with variation, defining key terms, and reproducing sounds with instruments or their own voices. These techniques might translate to teaching audiences to perceive auditory display and sonification, which, like music, uses the qualities sounds — timbre, tempo, pitch, etc. — to convey meaning.</dd>

    <dt class="col-sm-3 ">We are here to research sounds, so why look at video?</dt>
    <dd class="col-sm-9"><strong>Video analysis</strong> enables us to see what close listening looks like and observe how it happens in the whole body, rather than only in the ears and mind. <p>Further, video analysis allows us to consider <strong>listening as a sensory-social experience</strong> by observing interpersonal acts of listening.
    This is especially relevant for the live performance of <em>Switched on Pop</em>, where the hosts and audience can interact with each other.</p></dd>

      </dl>
    </dd>
  </dl>

</div>

<div class="container-fluid p-5 mb-4 rounded-1 bg-warning"><a class="anchor" id="Contributions" style="display: block; position: relative; top: -300px; visibility: hidden;"></a>
  <h2 class="display-9 fw-bold col-md-8" >Contributions for the auditory dislay and sonification community</h2>
<ul>
  <li>Demonstrating how video analysis can be useful for understanding listening behaviors;</li>
<li>Envisioning how techniques for teaching people how to listen to music might be applied to learning to listen to data sonifications.</li>
</ul>

</div>

<div class="container-fluid p-5 mb-4 rounded-1"> <a id="Video" style="display: block; position: relative; top: -300px; visibility: hidden;"></a>
  <h2 class="display-9 fw-bold col-md-8">The Video Clip</h2>
  <p class="fs-7">I analyzed an 80-second segment where the two podcast hosts, Charlie Harding and Nate Sloan,
  discuss the 2000 Britney Spears hit, "Oops!... I Did It Again,"</p>
  <p>The podcast hosts teach the live audience how the structure of the song, which has a two-part chorus, reflects the theme of the song, which is about grappling with multiple conflicting identities.
  First, everyone (hosts and audience) listen to an excerpt from the song. Then, Harding and Sloan lead a participatory activity: a two-part audience sing-a-long of the chorus.
Finally, Harding helps the audience interpret the song through explanatory and expository narrative. </p>
<p>Here's the clip:</p>
<div class="container-sm">
<video width="80%" controls>
  <source src="files/switched-on-pop-short1.mp4" type="video/mp4">
Your browser does not support the video tag.
</video>
</div>
  <p>You can view the entire <a href="https://www.youtube.com/watch?v=NHmYzVZoxhg">72-minute live event on YouTube</a>.</p>
</div>

<div class="container-fluid p-5 mb-4 rounded-1 bg-warning"><a id="Artifacts" style="display: block; position: relative; top: -300px; visibility: hidden;"></a>
  <h2 class="display-9 fw-bold col-md-8">Methods: Video Analysis Through Creating Analytic Artifacts</h2>
<p>To perform video analysis, you <strong>watch the same clip repeatedly</strong>, each time viewing with a different lens.
  As you watch, you create a series of <strong>interpretive, analytic artifacts</strong> that abstract data from the clip [Barron & Engle 2007, Derry et al 2010], like an ethnographer taking detailed field notes.
</p>
<p>The analytic artifacts I created for this project include (links open as PDFs):</p>
<div class="container">
  <div class="row row-cols-2">
    <div class="col"><h5>Activity Log</h5>  <p><a href="files/Wirfs-Brock-Activity-Log-B.pdf">80-second clip</a> | <a href="files/ActivityLogA.pdf">40 minutes of live show</a></p>
<img class="img-fluid" src="files/activity-log-image.png" >
    </div>
    <div class="col"><h5>Playscript</h5> <p><a href="files/Wirfs-Brock-Playscript.pdf">Phonetic transcript of speech and action</a></p>
<img class="img-fluid" src="files/playscript-image.png" href="files/Wirfs-Brock-Playscript.pdf">
    </div>
    <div class="col"><h5>Play-by-Play</h5><p><a href="files/Wirfs-Brock-PlayByPlay.pdf">Descriptive narrative of action</a></p>
<img class="img-fluid" src="files/play-by-play-image.png" >
    </div>
    <div class="col"><h5>Landscape Diagram</h5><p><a href="files/Wirfs-Brock-Landscape.pdf">Schematic diagram of key events</a></p>
<img class="img-fluid" src="files/landscape-image.png" >
    </div>
    <div class="col"><h5>Scroll</h5> <p><a href="files/scroll-video-view.mp4">Extended horizontal storyboard (video)</a></p>
<img class="img-fluid" src="files/scroll-image.png" >
    </div>
    <div class="col"><h5>Vignette</h5><p><a href="files/Wirfs-Brock_VIGNETTE.pdf">An analytic/interpretive description</a></p>
<img class="img-fluid" src="files/vignette-image.png" >
    </div>
  </div>
</div>
</div>


<div class="container-fluid p-5 mb-4 rounded-1 bg-info" ><a id="Findings" style="display: block; position: relative; top: -300px; visibility: hidden;"></a>

  <h2 class="display-9 fw-bold col-md-8">Key Findings</h2>
  <div style="max-width:400px; padding:10px" class="float-start">
    <img  src="files/puzzle-pieces.png" width="95%">
  </div>
  <p>Focusing on video drew my attention to four themes: </p>
  <ul>
<li>the interplay between scripted and unscripted action,</li>
<li>the sequencing of interaction to support learning,</li>
<li>what close listening <em>looks</em> like,</li>
<li>the role of embodiment in how people make sense of sounds.</li>
</ul>




<div class="accordion" id="accordionExample">
  <div class="accordion-item">
    <h2 class="accordion-header" id="headingOne">
      <button class="accordion-button collapsed " type="button" data-bs-toggle="collapse" data-bs-target="#collapseOne" aria-expanded="false" aria-controls="collapseOne">
        Scripted and Unscripted Action
      </button>
    </h2>
    <div id="collapseOne" class="accordion-collapse collapse" aria-labelledby="headingOne" data-bs-parent="#accordionExample">
      <div class="accordion-body">
        <p>At this live performance, Harding and Sloan, podcasters who typically hold the audience in their minds and interact with them at a distance and asynchronously, are now interacting with their audience in real time. The audience co-presence, visual modality, and live/real-time nature of this event throw Harding and Sloan out of their element.
        As they get into the flow of the performance, Harding and Sloan negotiate how to interact with each other and with the audience, and ultimately become more comfortable with the live medium. I focused on a clip near the <em>beginning</em> of the performance, when this negotiation is still tentative. The moments where Harding and Sloan stumble are revealing in terms of how learning to listen is an emergent, social interaction—like a moment during the sing-a-long where Harding loses the beat, starts laughing and looks to the audience to help him get back on track.

        <p>Perhaps in the moments where Harding and Sloan <strong>rely heavily on their scripts, they are taking on the role of “expert,”</strong> explicitly referencing knowledge they hope to relay to the audience.  Alternatively, in the moments where they are <strong>reacting in an unscripted way, they are engaging the implicit knowledge they have earned</strong>, recalling their practice as learners, and relaying that knowledge in a more informal—and perhaps more relatable—format to the audience.</p>
      </div>
    </div>
  </div>

  <div class="accordion-item">
    <h2 class="accordion-header" id="headingTwo">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseTwo" aria-expanded="false" aria-controls="collapseTwo">
        Sequencing and Structure of Interaction
      </button>
    </h2>
    <div id="collapseTwo" class="accordion-collapse collapse" aria-labelledby="headingTwo" data-bs-parent="#accordionExample">
      <div class="accordion-body">
        <p>I focused on the sing-a-long portion of the performance to explore an assertion: <em>Harding and Sloan attempt to teach a live audience to learn to listen to pop music analytically by stepping them through a <strong>structured, mediated sequence of learning activities.</strong></em> This sequence moves from active listening, to embodied collaborative creation (singing), to mediated interpretation (explanation). While we have little access to the audience’s external reactions or internal receptions of this teaching moment, we are able to see how Harding and Sloan respond and adapt, in real time, to the audience. Thus, we can use this scenario to identify patterns of learning to listen that we might emulate in other interactions where the goal is developing analytic listening skills. </p>
        <img src="files/structure-diagram.png" class="img-fluid">
        <figcaption class="figure-caption"><small><em>Landscape with labeled sub-sequences:
          <ul class="list-unstyled">
      <li>A: [0:00-0:12] A sound clip is playing. Here, Harding and Sloan are <strong>modeling active listening</strong> through their body movements and their gazes (at the computer, down).</li>
      <li>B: [0:12-0:27] Sloan is <strong>setting up the sing-a-long</strong> by explaining how it will work, gesturing to the portions of the room with his hands, and singing short excerpts with his voice. He is gazing at the audience to establish understanding, but switches to gazing at Harding to synchronize the count-off to start the sing-a-long.</li>
      <li>C: [0:27-0:36] Harding, Sloan, and the audience are <strong>singing along, performing</strong> two different parts of the chorus. Both Harding and Sloan are gazing at the audience, establishing a shared action and timing with them.</li>
      <li>D: [0:36-0:45] <strong>Debrief</strong> of the sing-a-long, where Harding and Sloan banter with each other (and to a lesser extent with the audience), diffuse any lingering tension, and set up for the next segment.</li>
      <li>E: [0:45 - 1:27] Sloan is performing an <strong>expository/explanatory monologue</strong>, where he interprets the meaning of the two-part chorus they all just collectively performed. After a brief set-up of looking at his script, he is looking at the audience to establish a connection with them. Throughout, he uses gestures to emphasize the points he is making.</li>
      <li>F: [1:27 - 1:29] Hand-off between Sloan and Harding, transitioning into Harding having the floor.</li></small></em></figcaption>
      </small>
      <p>This sequence <strong>bounces back and forth from demonstration to participation</strong>: Harding and Sloan demonstrate listening, while the audience simultaneously participates; next Sloan demonstrates singing, which the audience then mirrors.
        Through this toggling between demonstration and participation, suspense is building: Why are we focusing so much on this chorus and what can we learn from it? Finally, that <strong>suspense is resolved through Harding’s explanation</strong>.
      This is one potential pattern, which I am tentatively coding as <em><mark>[ demonstrate | participate | explain ]</mark></em>.

      <p>Harding and Sloan also employ other micro-structural actions throughout the performance, such as: <strong>defining existing musical terms</strong> (this is timbre, this is form, etc.), <strong>developing a new vocabulary</strong> unique to the event (referring to a fictionalized critic as “competent cheese” and referring back to him over and over), <strong>sign-posting</strong> (listing the concepts that they are going to learn, then returning to them by name).
        Perhaps patterns and sequences like these could be building blocks for auditory display and sonificartion designers as they teach audiences to listen.
      </p>
      </div>
    </div>
  </div>

  <div class="accordion-item">
    <h2 class="accordion-header" id="headingThree">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseThree" aria-expanded="false" aria-controls="collapseThree">
        What Close Listening Looks Like
      </button>
    </h2>
    <div id="collapseThree" class="accordion-collapse collapse" aria-labelledby="headingThree" data-bs-parent="#accordionExample">
      <div class="accordion-body">
        <p>Video analysis gives us access to gestures, posture, gaze, and other physical, non-verbal cues. In this live performance, when the hosts play music clips from their position on stage, they have nowhere to hide and are forced to <strong>stay on stage, remaining an object of visual interest</strong> for the audience. This can be awkward. Harding and Sloan diffuse this awkwardness by modeling active listening practices that engage their entire bodies. As they listen, they give the audience something to look at. What does this active listening entail?</p>

      <img src="files/not-that-innocent.gif" class="img-fluid">
      <figcaption class="figure-caption"><small><em>  As “Oops!...I Did it Again” plays, both Hading and Sloan have their <strong>eyes slightly downcast</strong>, as if narrowing their fields of vision so that they can focus on listening. Harding also appears to be looking at his laptop, monitoring how much time is left in the clip. Still, we can see his <strong>head nod ever so slightly</strong> to the rhythm of the final lines of the chorus (box B). Sloan demonstrates an even more explicit style of embodied listening, <strong>enacting the rhythm of the song with his foot</strong>, which moves in a circular motion, and his hands, which he raises from the arms of the chair, forms into fists near his lap, thumb on top almost like he is playing the drums. Finally, he pumps his fists up and down, grooving from his shoulders, to punctuate the beats of,  “I’m not that innocent." (box A) In doing so, he is demonstrating that it is perfectly ok, even preferable, to feel the song with his body, signaling to the audience that they can and should do the same. Although we cannot see the entire audience, we can see a few people in the front row, to Sloan’s left, subtly bobbing and swaying (box C) and to Harding’s right nodding (box D).
      </em></small></figcaption>

      <p>As they listen, Harding and Sloan both use their bodies, but in very different ways: Harding’s bodily movements are subtle, whereas Sloan’s are pronounced. But in both cases, they are normalizing the process of feeling sound with the body and inviting the audience to do the same: By extension, however you feel the sound with your body is ok. We don’t all listen with our bodies in the same way.</p>

    </div>
  </div>
</div>

  <div class="accordion-item">
    <h2 class="accordion-header" id="headingFour">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseFour" aria-expanded="false" aria-controls="collapseFour">
        Embodied Sonic Sensemaking
      </button>
    </h2>
    <div id="collapseFour" class="accordion-collapse collapse" aria-labelledby="headingFour" data-bs-parent="#accordionExample">
      <div class="accordion-body">
        <p>Harding and Sloan model embodiment through gesture as they <em>interpret/understand</em> sounds themselves (as learners) and <em>explain/communicate</em> those interpretations (as teachers). Embodiment rejects mind-body dualism and instead asserts that we <strong>think and act with our entire bodies</strong>. From the human-computer interaction tradition, I draw on Dourish, who writes that, “Embodied phenomena are ones we encounter directly rather than abstractly” and that “a disembodied brain could not experience the world in the same ways that we do, because our experience of the world is intimately tied to the ways in which we act in it” [Dourish 2004].</p>

        <p>I began my exploration of gesture in a playscript, where I did my best to describe them in detail with words (i.e. <em>((rasies just left hand to shoulder height, kind of opens and closes as if grasping))</em>). I then attempted to capture gesture through sketching (see below), and finally by creating animated GIFs.</p>
          <div style="max-width: 500px"><img src="files/gesture-sketch.png" class="img-fluid"></div>
            <figcaption class="figure-caption"><small><em>Gesture sketch illustrating “wrist flicking” motion to cue audience for chorus sing-a-long.</em></small>  </figcaption>

          <p>I focus on two specific instances of embodiment and their roles in learning to listen: <strong>how Harding uses social embodiment to co-construct the sing-a-long with the audience</strong>; and <strong>how Sloan uses gestural embodiment to explain the themes of the chorus</strong>.</p>

          <p>During the singalong, Harding starts to laugh halfway through the chorus, signaling that he is having trouble getting the words and melody right. In the front row, near Harding, we can see two audience members using their arms to count out the rhythm, moving their fist-shaped hands up and down to punctuate the “Oh baby baby” line. It is hard to tell for sure from the camera angle, but it seems Harding is looking directly at them, rather than at the entire audience, and coordinating his motion with them (see below). Perhaps those audience members are helping Harding through this embodied performance. This moment hints at how this embodied way of understanding music is happening socially, a co-constructed moment of embodied listening and understanding.

<br>
            <img src="files/charlie-audience-interaction.gif" class="img-fluid">
          <p><small><em>Harding looks at two audience members in the front row, who are grooving and moving their arms along with the beat of the song.</p></small></em>

          <p>After the sing-a-long, Sloan explains the meaning of the two-part “Oops!...I Did It Again” chorus. As Sloan readies himself for his expository monologue, he grabs his paper script from his lap, shuffles/organizes the papers, and glances at the script, readying himself for an extended period of exposition during which he will keep his eyes focused on the audience:<p>

          <blockquote class="blockquote fw-light fst-italic fs-6">"So at the end of this song, it raises a question: Who is Britney Spears? We still don't have an answer. She is multiple things at once. She is performing different identities. And this was, again, very, uh, vexing to a lot of critics when this song came out. But now maybe with the benefit of hindsight we can step back and see how masterfully this is done. She never truly reveals herself, she keeps us guessing, and in performing multiple aspects of her identity, she does something that we all do. None of us are just one thing, we are all composed of multitudes. And I think that’s what this song really captures.""</blockquote>

        <p>  This 40-second long segment of Sloan’s is distinct from the previous interactions: Sloan is looking almost exclusively at the audience, rather than over at Harding or down at his script; and Harding doesn’t interrupt Sloan until the very end. During this monologue, Sloan uses gestures liberally, even though he is a podcaster who is skilled at communicating with his voice alone.

          <p>These gestures serve to reinforce and punctuate, in an embodied way, the claims he is making about how to interpret music: Synchronously with the word “masterfully” he moves his hands in a motion as if he were playing the piano:
  <div style="max-width: 600px; padding: 10px"><img src="files/masterfully.gif" class="img-fluid"></div>
            <p>During the line, “in performing multiple aspects of her identity, she does something that we all do,” Sloan transitions from having his hands wide apart, moving up and down in a kind of popcorn motion, to bringing his hands close to his chest:
  <div style="max-width: 300px; padding: 10px"><img src="files/performing.gif" class="img-fluid"></div>
    <div style="max-width: 600px; padding: 10px"><img src="files/we-all-do.gif" class="img-fluid"></div>
    <div style="max-width: 600px; padding: 10px">  <img src="files/multitudes-captures.gif" class="img-fluid"></div>

        <p>  Throughout this explanation, Sloan is using tools that he had demonstrated while performing music (singing karaoke) and while listening (to the soundbite)— his gestural emphasis and his pacing—to communicate concepts that extend beyond the song itself, and indeed even beyond music. These gestures punctuate, emphasize, and reinforce the arguments he is making.

          <p>This resonates with Mitchell’s assertion that there are no purely visual media, that, “Seeing painting is seeing touching, seeing the hand gestures of the artist, which is why we are so rigorously prohibited from actually touching the canvas ourselves” [Mitchell 2005].  Similarly, hearing music is feeling the hand playing the piano and the jaw of the singer, as well as seeing those actions take place.

      <p>    Honing in on which elements of listening are visually salient, which lend themselves to being communicated through gesture, might open up new avenues for design. Perhaps learning to listen employs multiple, complementary types of sensemaking, such as aural/auditory, linguistic, social, even visual sensemaking. Perhaps embodied gestures —  singing, swaying, moving, articulating, even making social connections — which are disparate actions all grounded in the body, might serve as a bridge between the different, complementary types of sensemaking that contribute to learning to listen.


      </div>
    </div>
  </div>

</div>






</div>

<div class="container-fluid p-5 mb-4 rounded-1  " ><a id="FutureWork" style="display: block; position: relative; top: -300px; visibility: hidden;"></a>
  <h2 class="display-9 fw-bold col-md-8">Future Work</h2>
  <h4>Identifying Patterns for Learning to Listen</h4>
  <div style="max-width:300px; padding:10px" class="float-end">
    <img  src="files/headphones.png" width="95%">
  </div>
  <p>I’m curious how we, as designers, might foster this kind of embodied sensemaking through data, sound, and storytelling by building a community of practice — both by analyzing more examples, and by applying them to sonifications through design practice.
  <p>Thus, I’ll be continuing this work by <strong>identifying more interaction patterns that can help people learn how to listen</strong>. Other proto-patterns include reproducing sounds through singing or playing them, breaking songs down into their component audio parts, repeating sound patterns with slight variation each time, or labeling sounds with existing or new vocabulary.</p>
  <p>As an ICAD community, perhaps we could <strong>collaboratively surface these patterns</strong>, generating pattern libraries and resources for designers (similar to what [Bach et al 2018] did for data comics).
<h4>Video Analysis for Evaluation, Ideation, and Understanding Listening</h4>
  <p>Video analysis can help us understand how people interact with sounds by allowing us to consider embodied behaviors and environmental and social contexts. I think the ICAD community should be <strong>doing more video analysis for both evaluation of design concepts and exploration of listening as a contextual behavior</strong>. <p>Video analysis is an incredibly powerful method, but it takes time and is best done in a community of practitioners. I’d love to collaborate with anyone open to trying video analysis, perhaps by offering a tutorial or doing some pair-based analysis.</p>
</div>

<div class="container-fluid p-5 mb-4 rounded-1 bg-warning"><a id="Extras" style="display: block; position: relative; top: -300px; visibility: hidden;"></a>
  <h2 class="display-9 fw-bold col-md-8">Extras</h2>
  <h4>Video Version of this Presentation</h4>
  <p>A 5-minute video explaining the main contributions of this work.</p>
  <iframe width="560" height="315" src="https://www.youtube.com/embed/bshXmY-VPi4" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

</div>

<div class="container-fluid p-5 mb-4 rounded-1 ">
  <h3 class="display-9 fw-bold col-md-8">References</h3>

<p>Benjamin Bach, Zezhong Wang, Matteo Farinella, Dave Murray-Rust, and Nathalie Henry Riche. 2018. Design Patterns for Data Comics. In <em>Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems (CHI '18)</em>. Association for Computing Machinery, New York, NY, USA, Paper 38, 1–12. DOI:https://doi.org/10.1145/3173574.3173612</p>
<p>Brigid Barron and Randi A. Engle. 2007. Analyzing Data Derived from Video Records. National Science Foundation, Interagency Education Research Initiative, and the Data-Research and Development Center.</p>
<p>Sharon J. Derry, Roy D. Pea, Brigid Barron, Randi A. Engle, Frederick Erickson, Ricki Goldman, Rogers Hall, Timothy Koschmann, Jay L. Lemke, Miriam Gamoran Sherin, and Bruce L. Sherin. 2010. Conducting Video Research in the Learning Sciences: Guidance on Selection, Analysis, Technology, and Ethics. Journal of the Learning Sciences 19, 1: 3–53. https://doi.org/10.1080/10508400903452884</p>
<p>Paul Dourish. 2004. <em>Where the Action is: The Foundations of Embodied Interaction</em>. MIT Press.</p>
<p>W. J.T. Mitchell. 2005. There Are No Visual Media. <em>Journal of Visual Culture</em> 4, 2: 257–266. https://doi.org/10.1177/1470412905054673

  <h3 class="display-9 fw-bold col-md-8">Acknowledgments</h3>
  <p>Thank you to Arturo Cortez for teaching an amazing graduate-level course on video analysis (Fall 2020) and to Brian Keegan, my advisor, for his consistent, thoughtful feedback.
</div>

<div class="container-fluid p-5 mb-4 rounded-1 bg-info">
    <h3 class="display-9 fw-bold col-md-8">Contact Information</h3>
    <ul>
      <li>Email: wirfsbro@colorado.edu</li>
      <li><a href="http://jordanwb.com">Website</a></li>
        <li>Twitter: <a href="http://twitter.com/jordanwb">@jordanwb</a></li>
      </ul>

  </div>








  </body>
</html>
